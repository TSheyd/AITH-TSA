{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://developers.sber.ru/portal/products/lightautoml",
   "id": "89f619b9469341e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install -U lightautoml",
   "id": "6d37210fadbf23d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Standard libs\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "# Installed libraries\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# LAMA\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.addons.autots.base import AutoTS\n",
    "from lightautoml.dataset.roles import DatetimeRole\n",
    "# from lightautoml.automl.base import AutoML\n",
    "# from lightautoml.ml_algo.boost_cb import BoostCB\n",
    "# from lightautoml.ml_algo.linear_sklearn import LinearLBFGS\n",
    "# from lightautoml.pipelines.features.lgb_pipeline import LGBSeqSimpleFeatures\n",
    "# from lightautoml.pipelines.features.linear_pipeline import LinearTrendFeatures\n",
    "# from lightautoml.pipelines.ml.base import MLPipeline\n",
    "# from lightautoml.reader.base import DictToPandasSeqReader\n",
    "# from lightautoml.automl.blend import WeightedBlender\n",
    "# from lightautoml.ml_algo.random_forest import RandomForestSklearn\n",
    "\n",
    "# Disable warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "class LamaTSA:\n",
    "    \n",
    "    def __init__(self, store_id, item_id, period='7'):\n",
    "        \"\"\"\n",
    "        :param str store_id: \n",
    "        :param str item_id: \n",
    "        :param str period: \n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"preprocessing loaded data...\")\n",
    "        self.store_id = f\"STORE_{store_id}\" if isinstance(store_id, int) or store_id.isnumeric() else store_id\n",
    "        self.item_id = f\"{self.store_id}_{item_id}\" if isinstance(item_id, int) or item_id.isnumeric() else item_id\n",
    "        \n",
    "        periods = {\"w\": 7, \"m\": 30, \"q\": 90}        \n",
    "        self.period = periods.get(period)\n",
    "        if not self.period:\n",
    "            raise ValueError(f'Incorrect period value: {period}\\nSupported values: \"w\" - week, \"m\" - month, \"q\" - quarter')\n",
    "        \n",
    "        print(\"LamaTSA init complete!\")\n",
    "\n",
    "    def load_data(self, sales, dates, prices) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Загрузка и обработка данных\n",
    "        :param str sales: путь до файла sales.csv\n",
    "        :param str dates: путь до файла dates.csv\n",
    "        :param str prices: путь до файла prices.csv\n",
    "        :return: объединенный предобработанный DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        sales = pd.read_csv(sales)\n",
    "        dates = pd.read_csv(dates)\n",
    "        prices = pd.read_csv(prices)\n",
    "        \n",
    "        df = pd.merge(sales, dates, on='date_id')\n",
    "        df = pd.merge(df, prices, on=['store_id', 'item_id', 'wm_yr_wk'])\n",
    "        \n",
    "        df = self.preprocess_data(df)\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df) -> pd.DataFrame:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.loc[df['store_id'] == self.store_id, ['item_id', 'date', 'cnt']]\n",
    "        df = df.sort_values(by=['date'])\n",
    "        \n",
    "        # remove trailing (from start) zeros\n",
    "        df = df.loc[df.cnt.ne(0).idxmax():]\n",
    "        \n",
    "        # fill empty periods? \n",
    "        # df['']\n",
    "        \n",
    "        # MA smoothing\n",
    "        # df.cnt = df.cnt.rolling(7).mean()\n",
    "        # df = df.dropna()\n",
    "        \n",
    "        # events\n",
    "        print(f\"data shape: {df.shape}\\nselected class count: {df.loc[df.item_id == self.item_id].shape[0]}\")\n",
    "        return df.reset_index(drop=True)\n",
    "    \n",
    "    def split_train_test(self, df) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        (опционально) сплит датасета на train/test для простого backtesting'а\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        \n",
    "        test_start = df[df['item_id'] == self.item_id]['date'].values[-self.period]\n",
    "        train = df[df['date'] < test_start].copy()\n",
    "        test = df[df['date'] >= test_start].copy()\n",
    "        return train, test\n",
    "        \n",
    "    def define_training_task(self):\n",
    "        \n",
    "        # define task\n",
    "        # \"multi:reg\": [\"mae\", \"mse\"]\n",
    "        task = Task(\"multi:reg\", greater_is_better=False, metric=\"mae\", loss=\"mae\")\n",
    "        \n",
    "        # configure model\n",
    "        seq_params = {\n",
    "            \"seq0\": {\n",
    "                \"case\": \"next_values\",                  \n",
    "                \"params\": {\n",
    "                    \"n_target\": self.period,                \n",
    "                    \"history\": self.period,                              \n",
    "                    \"step\": 1, \n",
    "                    \"from_last\": True,\n",
    "                    \"test_last\": True\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        transformers_params = {\n",
    "            \"lag_features\": self.period,      \n",
    "            \"lag_time_features\": self.period, \n",
    "        }\n",
    "        \n",
    "        # time_series_trend_params = {\n",
    "        #     'trend': False,\n",
    "        #     'train_on_trend': False,\n",
    "        #     'trend_type': 'decompose',  # 'decompose', 'decompose_STL', 'linear', 'rolling'\n",
    "        #     'trend_size': 1, \n",
    "        #     'decompose_period': 30, \n",
    "        #     'detect_step_quantile': 0.01, \n",
    "        #     'detect_step_window': 1, \n",
    "        #     'detect_step_threshold': 0.7,\n",
    "        #     'rolling_size': 1, \n",
    "        #     'verbose': 0\n",
    "        # }\n",
    "        \n",
    "        automl = AutoTS(\n",
    "            task,\n",
    "            reader_params = {\n",
    "                \"seq_params\": seq_params\n",
    "            },\n",
    "            time_series_trend_params={\n",
    "                \"trend\": False,  # detrend before main use\n",
    "                # \"decompose_period\": self.period\n",
    "            },\n",
    "            time_series_pipeline_params=transformers_params\n",
    "        )\n",
    "        return automl\n",
    "        \n",
    "    def train_model(self, train_dataset, verbose=4):\n",
    "        # load dataset\n",
    "        univariate_train = train_dataset[train_dataset['item_id'] == self.item_id].drop(\"item_id\", axis=1)\n",
    "                \n",
    "        # define roles\n",
    "        univariate_roles = {\n",
    "           \"target\": 'cnt',\n",
    "           DatetimeRole(seasonality=('d', 'm', 'wd'), base_date=True): 'date',  # + y ?\n",
    "        }\n",
    "        \n",
    "        # train model        \n",
    "        model = self.define_training_task()\n",
    "        univariate_train_pred, _ = model.fit_predict(univariate_train, univariate_roles, verbose=verbose)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def eval_model(self, model, train_dataset, test_dataset):\n",
    "        \"\"\"\n",
    "        Подсчет метрики MAE, построение графика предсказаний для наглядности\n",
    "        :param model: модель \n",
    "        :param pd.DataFrame train_dataset: \n",
    "        :param pd.DataFrame test_dataset: \n",
    "        :return: fig, mae\n",
    "        \"\"\"\n",
    "        train_dataset = train_dataset[train_dataset['item_id'] == self.item_id].drop(\"item_id\", axis=1)\n",
    "        test_dataset = test_dataset[(test_dataset['item_id'] == self.item_id)].drop(\"item_id\", axis=1)[:self.period]\n",
    "        \n",
    "        \n",
    "        print(train_dataset)\n",
    "        fcst, _ = model.predict(train_dataset)\n",
    "        # print(f'forecast {(len(fcst))}: {fcst};\\ntest size: {len(test_dataset.cnt.values)} {test_dataset}')\n",
    "        \n",
    "        mae = mean_absolute_error(test_dataset.cnt.values, fcst)\n",
    "        print(f\"MAE: {mae}\")      \n",
    "        \n",
    "        # plot predictions\n",
    "        fig = plt.figure(figsize=(13, 5))\n",
    "        last_N = min(len(train_dataset), len(fcst)*5)  # historical data\n",
    "        plt.plot(\n",
    "            train_dataset['date'][-last_N:], \n",
    "            train_dataset['cnt'][-last_N:], \n",
    "            c=\"#003865\", \n",
    "            label=\"train\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            test_dataset['date'], \n",
    "            test_dataset['cnt'], \n",
    "            c=\"#EF5B0C\", \n",
    "            label=\"test\", \n",
    "            marker=\"o\", \n",
    "            markersize=4\n",
    "        )\n",
    "        plt.plot(\n",
    "            test_dataset['date'], \n",
    "            fcst, \n",
    "            c=\"#3CCF4E\", \n",
    "            label=\"forecast\", \n",
    "            marker=\"o\", \n",
    "            markersize=4\n",
    "        )\n",
    "\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.title(f\"Train, test and forecasts of LightAutoML for product_id {self.item_id}\")\n",
    "        plt.legend()        \n",
    "        return fig, mae\n",
    "        \n",
    "    def save_model(self, model, path) -> str:\n",
    "        \"\"\"\n",
    "        Сохранение модели\n",
    "        :param model: модель \n",
    "        :param str path: путь\n",
    "        :return: path\n",
    "        \"\"\"\n",
    "        joblib.dump(model, path)\n",
    "        print(f\"Model saved in {path}\")\n",
    "        return path\n",
    "        \n",
    "    def load_model(self, path):\n",
    "        \"\"\"\n",
    "        Загрузка модели\n",
    "        :param str path: путь до модели \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            raise ValueError(\"path to model not found!\")\n",
    "        \n",
    "        try:\n",
    "            model = joblib.load(path)\n",
    "            print(f'model {path} loaded successfully')\n",
    "        except Exception as e:\n",
    "            print(f'Error loading model: {e}')\n",
    "            return 0\n",
    "        return model\n",
    "\n",
    "    def predict(self, model, pred_df) -> list: \n",
    "        \"\"\"\n",
    "        Инференс модели\n",
    "        :param model: модель\n",
    "        :param pred_df: DataFrame с датами для предсказаний\n",
    "        :return: list (cnt)\n",
    "        \"\"\"\n",
    "        pred = pred_df[pred_df['item_id'] == self.item_id].drop(\"item_id\", axis=1)\n",
    "        fcst, _ = model.predict(pred)\n",
    "\n",
    "        print(fcst, \"\\n\")\n",
    "        print(f\"MAE: {mean_absolute_error(pred.cnt.values, fcst)}\")\n",
    "        return fcst\n",
    "        "
   ],
   "id": "9a29493432408e1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "i = LamaTSA(\n",
    "    store_id='2',  # selected store\n",
    "    item_id='586',  # selected item\n",
    "    period='m'  # w / m / q\n",
    ")\n",
    "\n",
    "train_df = i.load_data(\n",
    "    sales=\"data/shop_sales.csv\", \n",
    "    dates=\"data/shop_sales_dates.csv\", \n",
    "    prices=\"data/shop_sales_prices.csv\"\n",
    ")\n",
    "\n",
    "test_df = i.load_data(\n",
    "    sales=\"data/shop_sales_test.csv\", \n",
    "    dates=\"data/shop_sales_dates_test.csv\", \n",
    "    prices=\"data/shop_sales_prices_test.csv\"\n",
    ")\n"
   ],
   "id": "65b3de2881fe7184",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_df",
   "id": "e1e6aff743a3e5e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = i.train_model(train_df)",
   "id": "4d1c0eb8d98f2f49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "i.save_model(model, 'models/model_f_2.pkl')",
   "id": "289f033e959baaf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = i.load_model('models/model_f_2.pkl')",
   "id": "ee73ceb778456a7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "fig, mae = i.eval_model(model, train_df, test_df)",
   "id": "835e12d67654047c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
